{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Time series forecasting\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Time series are an ubiquitous type of data in all types of processes. Producing forecasts for them can be highly valuable in domains like retail or industrial manufacture, among many others.\n",
    "\n",
    "Lightwood supports time series forecasting (both univariate and multivariate inputs), handling many of the pain points commonly associated with setting up a manual time series predictive pipeline. \n",
    "\n",
    "In this tutorial, we will train a lightwood predictor and analyze its forecasts for the task of counting sunspots in monthly intervals.\n",
    "\n",
    "## Load data\n",
    "\n",
    "Let's begin by loading the dataset and looking at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:08:15.087387Z",
     "iopub.status.busy": "2021-12-08T18:08:15.086668Z",
     "iopub.status.idle": "2021-12-08T18:08:15.508304Z",
     "shell.execute_reply": "2021-12-08T18:08:15.508810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Sunspots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1749-01</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1749-02</td>\n",
       "      <td>62.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749-03</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1749-04</td>\n",
       "      <td>55.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1749-05</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>1983-08</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>1983-09</td>\n",
       "      <td>50.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>1983-10</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>1983-11</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>1983-12</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2820 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  Sunspots\n",
       "0     1749-01      58.0\n",
       "1     1749-02      62.6\n",
       "2     1749-03      70.0\n",
       "3     1749-04      55.7\n",
       "4     1749-05      85.0\n",
       "...       ...       ...\n",
       "2815  1983-08      71.8\n",
       "2816  1983-09      50.3\n",
       "2817  1983-10      55.8\n",
       "2818  1983-11      33.3\n",
       "2819  1983-12      33.4\n",
       "\n",
       "[2820 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/monthly_sunspots/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very simple dataset. It's got a single column that specifies the month in which the measurement was done, and then in the 'Sunspots' column we have the actual quantity we are interested in forecasting. As such, we can characterize this as a univariate time series problem.\n",
    "\n",
    "## Define the predictive task\n",
    "\n",
    "We will use Lightwood high level methods to state what we want to predict. As this is a time series task (because we want to leverage the notion of time to predict), we need to specify a set of arguments that will activate Lightwood's time series pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:08:15.513373Z",
     "iopub.status.busy": "2021-12-08T18:08:15.511542Z",
     "iopub.status.idle": "2021-12-08T18:08:18.121730Z",
     "shell.execute_reply": "2021-12-08T18:08:18.122177Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2154:No torchvision detected, image encoder not supported\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:No torchvision/pillow detected, image encoder not supported\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:08:18.130988Z",
     "iopub.status.busy": "2021-12-08T18:08:18.130420Z",
     "iopub.status.idle": "2021-12-08T18:08:18.133499Z",
     "shell.execute_reply": "2021-12-08T18:08:18.133933Z"
    }
   },
   "outputs": [],
   "source": [
    "tss = {'nr_predictions': 6,   # the predictor will learn to forecast what the next semester counts will look like (6 data points at monthly intervals -> 6 months)\n",
    "       'order_by': ['Month'], # what column is used to order the entire datset\n",
    "       'window': 12           # how many past values to consider for emitting predictions\n",
    "      }\n",
    "\n",
    "pdef = ProblemDefinition.from_dict({'target': 'Sunspots',         # specify the column to forecast\n",
    "                                    'timeseries_settings': tss    # pass along all time series specific parameters\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a very simple train-test split, leaving 10% of the data to check the forecasts that our predictor will produce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:08:18.141327Z",
     "iopub.status.busy": "2021-12-08T18:08:18.140031Z",
     "iopub.status.idle": "2021-12-08T18:08:18.143389Z",
     "shell.execute_reply": "2021-12-08T18:08:18.142894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2538, 2) (282, 2)\n"
     ]
    }
   ],
   "source": [
    "cutoff = int(len(df)*0.9)\n",
    "\n",
    "train = df[:cutoff]\n",
    "test = df[cutoff:]\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the predictor object\n",
    "\n",
    "Now, we can generate code for a machine learning model by using our problem definition and the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:08:18.149196Z",
     "iopub.status.busy": "2021-12-08T18:08:18.148022Z",
     "iopub.status.idle": "2021-12-08T18:08:18.952812Z",
     "shell.execute_reply": "2021-12-08T18:08:18.952298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2154:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Analyzing a sample of 2467\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:from a total population of 2820, this is equivalent to 87.5% of your data.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Infering type for: Month\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Column Month has data type date\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Infering type for: Sunspots\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Column Sunspots has data type float\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/helpers/text.py:242: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  randomness_per_index.append(S / np.log(N))\n",
      "\u001b[32mINFO:lightwood-2154:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Finished statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Unable to import black formatter, predictor code might be a bit ugly.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import (\n",
    "    json_ai_from_problem,\n",
    "    code_from_json_ai,\n",
    "    predictor_from_code\n",
    ")\n",
    "\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "\n",
    "# uncomment this to see the generated code:\n",
    "# print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Okay, everything is ready now for our predictor to learn based on the training data we will provide.\n",
    "\n",
    "Internally, lightwood cleans and reshapes the data, featurizes measurements and timestamps, and comes up with a handful of different models that will be evaluated to keep the one that produces the best forecasts.\n",
    "\n",
    "Let's train the predictor. This should take a couple of minutes, at most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:08:18.958472Z",
     "iopub.status.busy": "2021-12-08T18:08:18.956619Z",
     "iopub.status.idle": "2021-12-08T18:21:17.610568Z",
     "shell.execute_reply": "2021-12-08T18:21:17.611334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2154:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Performing statistical analysis on data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Finished statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Cleaning the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Transforming timeseries data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Using 1 processes to reshape.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Splitting the data into train/test\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Preparing the encoders\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Encoder prepping dict length of: 1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Done running for: Sunspots\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [1/100000] average_loss = 0.01750784402553338\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [2/100000] average_loss = 0.007003392313073687\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [3/100000] average_loss = 0.005434535743893759\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [4/100000] average_loss = 0.0047695753923021975\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [5/100000] average_loss = 0.004572915686408609\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [6/100000] average_loss = 0.004430522460444796\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [7/100000] average_loss = 0.0042531448571360465\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [8/100000] average_loss = 0.004267357041873364\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [9/100000] average_loss = 0.004190274744234236\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [10/100000] average_loss = 0.004175569959989571\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [11/100000] average_loss = 0.004149997531845774\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [12/100000] average_loss = 0.004156010633174676\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [13/100000] average_loss = 0.004173728322606997\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [14/100000] average_loss = 0.004146233540282775\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [15/100000] average_loss = 0.004159609850776592\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [16/100000] average_loss = 0.004153083168270291\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [17/100000] average_loss = 0.0041878944990305055\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [18/100000] average_loss = 0.00439742870380916\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [19/100000] average_loss = 0.004598384015196885\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [20/100000] average_loss = 0.004352907661589975\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [21/100000] average_loss = 0.0042240079981641886\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [22/100000] average_loss = 0.003986425293306127\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [23/100000] average_loss = 0.003991363632073544\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [24/100000] average_loss = 0.00394517953153667\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [25/100000] average_loss = 0.0040034270615377275\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [26/100000] average_loss = 0.003910830319449697\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [27/100000] average_loss = 0.003853997864781662\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [28/100000] average_loss = 0.0037486438367078686\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [29/100000] average_loss = 0.003712086851876588\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [30/100000] average_loss = 0.0036641826849894013\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [31/100000] average_loss = 0.003772246832396646\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [32/100000] average_loss = 0.0037095182283329673\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [33/100000] average_loss = 0.0036380832228685637\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [34/100000] average_loss = 0.0036899787479858265\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [35/100000] average_loss = 0.0035916260213651506\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [36/100000] average_loss = 0.003728403062306853\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:time series encoder epoch [37/100000] average_loss = 0.0036718556999951447\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Featurizing the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training the mixers\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\u001b[33mWARNING:lightwood-2154:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\u001b[0m\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\u001b[33mWARNING:lightwood-2154:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\u001b[0m\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\u001b[33mWARNING:lightwood-2154:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\u001b[0m\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\u001b[33mWARNING:lightwood-2154:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\u001b[0m\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\u001b[33mWARNING:lightwood-2154:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\u001b[0m\n",
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\u001b[33mWARNING:lightwood-2154:LightGBM running on CPU, this somewhat slower than the GPU version, consider using a GPU instead\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
      "\u001b[32mINFO:lightwood-2154:Loss of 0.6233991384506226 with learning rate 0.0001\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss of 0.7037602663040161 with learning rate 0.00014\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Found learning rate of: 0.0001\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 1: 0.6617613285779953\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 2: 0.6590867787599564\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 3: 0.6558134853839874\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 4: 0.6519927233457565\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 5: 0.6477000266313553\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 6: 0.6430090367794037\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 7: 0.6347611397504807\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 8: 0.6290576010942459\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 9: 0.6230623722076416\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 10: 0.6167891323566437\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 11: 0.6102726012468338\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 12: 0.6035372018814087\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 13: 0.5922587811946869\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 14: 0.5848198086023331\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 15: 0.5771614760160446\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 16: 0.5692700147628784\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 17: 0.5611817836761475\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 18: 0.5529830902814865\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 19: 0.5397608578205109\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 20: 0.5313711762428284\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 21: 0.5230549722909927\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 22: 0.5149609446525574\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 23: 0.5070468783378601\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 24: 0.49918878078460693\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 25: 0.4865911900997162\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 26: 0.47867877781391144\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 27: 0.470754474401474\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 28: 0.46281756460666656\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 29: 0.45490172505378723\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 30: 0.4470899626612663\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 31: 0.4347016215324402\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 32: 0.42702627182006836\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 33: 0.4194183945655823\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 34: 0.41187478601932526\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 35: 0.40443937480449677\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 36: 0.397148959338665\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 37: 0.38572316616773605\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 38: 0.37874338775873184\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 39: 0.37186072766780853\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 40: 0.3650688901543617\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 41: 0.358425036072731\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 42: 0.3519923985004425\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 43: 0.34202996641397476\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 44: 0.33604998141527176\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 45: 0.3302934467792511\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 46: 0.32476000487804413\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 47: 0.31943386793136597\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 48: 0.31440506130456924\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 49: 0.3067617043852806\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 50: 0.302204005420208\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 51: 0.2978372648358345\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 52: 0.2935965433716774\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 53: 0.28946246206760406\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 54: 0.2855726107954979\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 55: 0.27974558621644974\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 56: 0.2762824669480324\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 57: 0.2729584127664566\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 58: 0.26977550983428955\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 59: 0.26670923084020615\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 60: 0.2638510763645172\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 61: 0.2595043033361435\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 62: 0.25693606585264206\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 63: 0.2544870004057884\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 64: 0.2521001324057579\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 65: 0.24974262714385986\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 66: 0.24751442670822144\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 67: 0.24407555907964706\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 68: 0.24196476489305496\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 69: 0.2398938685655594\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 70: 0.2378729209303856\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 71: 0.23588719218969345\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 72: 0.2340329810976982\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 73: 0.23125949501991272\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 74: 0.22959399968385696\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 75: 0.22800986468791962\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 76: 0.22653044015169144\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 77: 0.22507306933403015\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 78: 0.2237185686826706\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 79: 0.22162490338087082\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 80: 0.22030753642320633\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 81: 0.21902070939540863\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 82: 0.21774762123823166\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 83: 0.21650397032499313\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 84: 0.21535537391901016\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 85: 0.21364851295948029\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 86: 0.21262715011835098\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 87: 0.2116394340991974\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 88: 0.2106684222817421\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 89: 0.2097397893667221\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 90: 0.2088611125946045\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 91: 0.2075318619608879\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 92: 0.20675189048051834\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 93: 0.20599757879972458\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 94: 0.20526033639907837\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 95: 0.20453806221485138\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 96: 0.20388613641262054\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 97: 0.20294446498155594\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 98: 0.2023930475115776\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 99: 0.20189081132411957\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 100: 0.20143171399831772\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 101: 0.20097894221544266\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 102: 0.2005634531378746\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 103: 0.19999956339597702\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 104: 0.19965513050556183\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 105: 0.19932125508785248\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 106: 0.19900639355182648\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 107: 0.19869227707386017\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 108: 0.19841187447309494\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 109: 0.19800211489200592\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 110: 0.1977458819746971\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 111: 0.19749976694583893\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 112: 0.1972552090883255\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 113: 0.1970275193452835\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 114: 0.19681121408939362\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 115: 0.19647308439016342\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 116: 0.19626808166503906\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 117: 0.1960633397102356\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 118: 0.1958710178732872\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 119: 0.19567545503377914\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 120: 0.1954973191022873\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 121: 0.19523821026086807\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 122: 0.1950712352991104\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 123: 0.19491016119718552\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 124: 0.1947605088353157\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 125: 0.19459708780050278\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 126: 0.19443923979997635\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 127: 0.19419902563095093\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 128: 0.19404493272304535\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 129: 0.19389192014932632\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 130: 0.1937338411808014\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 131: 0.19358301907777786\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 132: 0.193425714969635\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 133: 0.19316963106393814\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 134: 0.19303224235773087\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 135: 0.19287363439798355\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 136: 0.19271200150251389\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 137: 0.19254827499389648\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 138: 0.19239795953035355\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 139: 0.19215576350688934\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 140: 0.19200527667999268\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 141: 0.19186212867498398\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 142: 0.1917346939444542\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 143: 0.191590815782547\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 144: 0.19141872972249985\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 145: 0.19116847217082977\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 146: 0.19101449847221375\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 147: 0.1909051537513733\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 148: 0.19087745249271393\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 149: 0.19061629474163055\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 150: 0.19042475521564484\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 151: 0.19016872346401215\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 152: 0.19001216441392899\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 153: 0.1899031549692154\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 154: 0.18984626978635788\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 155: 0.18962448090314865\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 156: 0.18944908678531647\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 157: 0.18917229771614075\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 158: 0.1890169456601143\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 159: 0.18895412236452103\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 160: 0.18885599821805954\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 161: 0.18860241025686264\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 162: 0.18840837478637695\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 163: 0.18816183507442474\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 164: 0.18800272792577744\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 165: 0.18792204558849335\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 166: 0.18785516917705536\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 167: 0.1876014694571495\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 168: 0.18741513788700104\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 169: 0.18715502321720123\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 170: 0.18699640780687332\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 171: 0.1869453489780426\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 172: 0.18687434494495392\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 173: 0.18658219277858734\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 174: 0.18636548519134521\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 175: 0.18612536042928696\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 176: 0.18596408516168594\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 177: 0.1858159825205803\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 178: 0.18577438592910767\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 179: 0.18551477044820786\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 180: 0.18531598150730133\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 181: 0.18508345633745193\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 182: 0.1849103569984436\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 183: 0.18485111743211746\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 184: 0.18486561626195908\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 185: 0.1845666840672493\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 186: 0.18429189920425415\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 187: 0.18403545767068863\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 188: 0.18388332426548004\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 189: 0.18375267088413239\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 190: 0.18370416015386581\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 191: 0.18342243880033493\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 192: 0.18320219963788986\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 193: 0.18300434201955795\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 194: 0.18283292651176453\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 195: 0.18279945850372314\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 196: 0.18273275345563889\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 197: 0.1825052574276924\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 198: 0.1822245568037033\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 199: 0.18195556104183197\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 200: 0.18182165920734406\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 201: 0.18177411705255508\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 202: 0.18179136514663696\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 203: 0.18147604167461395\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 204: 0.18120186775922775\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 205: 0.1809777095913887\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 206: 0.18082815408706665\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 207: 0.1808546707034111\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 208: 0.18072474747896194\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 209: 0.18054744601249695\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 210: 0.18031249940395355\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 211: 0.18001287430524826\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 212: 0.17994334548711777\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 213: 0.17993827164173126\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 214: 0.1799386739730835\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 215: 0.17965131998062134\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 216: 0.17934871464967728\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 217: 0.17914705723524094\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 218: 0.1789635792374611\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 219: 0.1789270043373108\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 220: 0.17887423187494278\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 221: 0.17867712676525116\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 222: 0.17850036919116974\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 223: 0.17824236303567886\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 224: 0.1781574785709381\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 225: 0.17816752940416336\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 226: 0.17835140228271484\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 1: 0.14165862717411734\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 2: 0.14080426503311505\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 3: 0.14263895831324838\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 4: 0.14150805229490454\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 5: 0.14264232055707413\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM models for array prediction\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM model\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:A single GBM iteration takes 0.1 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training GBM (<module 'lightgbm' from '/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/__init__.py'>) with 882 iterations given 110.33333333333333 seconds constraint\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Lightgbm model contains 24 weak estimators\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 25 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_data.data_frame[self.target] = dev_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM model\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:A single GBM iteration takes 0.1 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training GBM (<module 'lightgbm' from '/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/__init__.py'>) with 882 iterations given 110.33333333333333 seconds constraint\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Lightgbm model contains 28 weak estimators\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 29 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_data.data_frame[self.target] = dev_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM model\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:A single GBM iteration takes 0.1 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training GBM (<module 'lightgbm' from '/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/__init__.py'>) with 882 iterations given 110.33333333333333 seconds constraint\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Lightgbm model contains 31 weak estimators\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 32 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_data.data_frame[self.target] = dev_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM model\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:A single GBM iteration takes 0.1 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training GBM (<module 'lightgbm' from '/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/__init__.py'>) with 882 iterations given 110.33333333333333 seconds constraint\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Lightgbm model contains 25 weak estimators\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 26 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_data.data_frame[self.target] = dev_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM model\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:A single GBM iteration takes 0.1 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training GBM (<module 'lightgbm' from '/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/__init__.py'>) with 882 iterations given 110.33333333333333 seconds constraint\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Lightgbm model contains 25 weak estimators\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 26 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_data.data_frame[self.target] = dev_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting LGBM model\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:A single GBM iteration takes 0.1 seconds\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Training GBM (<module 'lightgbm' from '/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/__init__.py'>) with 882 iterations given 110.33333333333333 seconds constraint\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Lightgbm model contains 18 weak estimators\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 19 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = original_target_train\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev_data.data_frame[self.target] = original_target_dev\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting sktime forecaster for array prediction\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Ensembling the mixer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Mixer: Neural got accuracy: 0.5276758959484122\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Mixer: LightGBMArray got accuracy: 0.4675135472669374\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Mixer: SkTime got accuracy: 0.21481464258617453\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Picked best mixer: Neural\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Analyzing the ensemble of mixers\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:The block ICP is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:The block AccStats is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Adjustment on validation requested.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating the mixers\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 1: 0.1423094136019548\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 2: 0.14200890312592188\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 3: 0.14406046519676843\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 4: 0.1433039369682471\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Loss @ epoch 5: 0.14418865367770195\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating array of LGBM models...\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 26 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 30 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 33 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 27 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1.5 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 27 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = train_data.data_frame[f'{self.target}_timestep_{timestep}']\n",
      "\u001b[32mINFO:lightwood-2154:Updating lightgbm model with 1 iterations\u001b[0m\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/hostedtoolcache/Python/3.9.9/x64/lib/python3.9/site-packages/lightgbm/engine.py:240: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32mINFO:lightwood-2154:Model now has a total of 20 weak estimators\u001b[0m\n",
      "/home/runner/work/lightwood/lightwood/lightwood/mixer/lightgbm_array.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data.data_frame[self.target] = original_target_train\n",
      "\u001b[32mINFO:lightwood-2154:Started fitting sktime forecaster for array prediction\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictor.learn(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Once the predictor has trained, we can use it to generate 6-month forecasts for each of the test set data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:21:17.616427Z",
     "iopub.status.busy": "2021-12-08T18:21:17.614156Z",
     "iopub.status.idle": "2021-12-08T18:21:27.048586Z",
     "shell.execute_reply": "2021-12-08T18:21:27.048119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2154:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Cleaning the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Transforming timeseries data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:Featurizing the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:The block ICP is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:The block AccStats is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2154:AccStats.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "forecasts = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how a single row might look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:21:27.063400Z",
     "iopub.status.busy": "2021-12-08T18:21:27.061932Z",
     "iopub.status.idle": "2021-12-08T18:21:27.066178Z",
     "shell.execute_reply": "2021-12-08T18:21:27.066685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>order_Month</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[71.74984833427635, 72.36395430189121, 67.2483...</td>\n",
       "      <td>[-273024000.0, -270345600.0, -267667200.0, -26...</td>\n",
       "      <td>[0.69, 0.69, 0.69, 0.69, 0.69, 0.69]</td>\n",
       "      <td>[51.087893493030805, 51.701999460645666, 46.58...</td>\n",
       "      <td>[92.4118031755219, 93.02590914313676, 87.91030...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           prediction  \\\n",
       "10  [71.74984833427635, 72.36395430189121, 67.2483...   \n",
       "\n",
       "                                          order_Month  \\\n",
       "10  [-273024000.0, -270345600.0, -267667200.0, -26...   \n",
       "\n",
       "                              confidence  \\\n",
       "10  [0.69, 0.69, 0.69, 0.69, 0.69, 0.69]   \n",
       "\n",
       "                                                lower  \\\n",
       "10  [51.087893493030805, 51.701999460645666, 46.58...   \n",
       "\n",
       "                                                upper  \n",
       "10  [92.4118031755219, 93.02590914313676, 87.91030...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.iloc[[10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that the point `prediction` has associated `lower` and `upper` bounds that are a function of the estimated `confidence` the model has on its own output. Apart from this, `order_Month` yields the timestamps of each prediction, the `anomaly` tag will let you know if the observed value falls outside of the predicted region. \n",
    "\n",
    "\n",
    "## Visualizing a forecast\n",
    "\n",
    "Okay, time series are much easier to appreciate through plots. Let's make one:\n",
    "\n",
    "NOTE: We will use `matplotlib` to generate a simple plot of these forecasts. If you want to run this notebook locally, you will need to `pip install matplotlib` for the following code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:21:27.071531Z",
     "iopub.status.busy": "2021-12-08T18:21:27.070207Z",
     "iopub.status.idle": "2021-12-08T18:21:27.072153Z",
     "shell.execute_reply": "2021-12-08T18:21:27.072598Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-08T18:21:27.082555Z",
     "iopub.status.busy": "2021-12-08T18:21:27.082018Z",
     "iopub.status.idle": "2021-12-08T18:21:27.279057Z",
     "shell.execute_reply": "2021-12-08T18:21:27.278548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot([None for _ in range(forecasts.shape[0])] + forecasts.iloc[-1]['prediction'], color='purple', label='point prediction')\n",
    "plt.plot([None for _ in range(forecasts.shape[0])] + forecasts.iloc[-1]['lower'], color='grey')\n",
    "plt.plot([None for _ in range(forecasts.shape[0])] + forecasts.iloc[-1]['upper'], color='grey')\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('# sunspots')\n",
    "plt.title(\"Forecasted amount of sunspots for the next semester\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we have gone through how you can train a machine learning model with Lightwood to produce forecasts for a univariate time series task.\n",
    "\n",
    "There are additional parameters to further customize your timeseries settings and/or prediction insights, so be sure to check the rest of the documentation."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
