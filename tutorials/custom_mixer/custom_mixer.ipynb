{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Implementing a custom mixer in Lightwood\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Mixers are the center piece of lightwood, tasked with learning the mapping between the encoded feature and target representation\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this tutorial we'll be trying to implement a sklearn random forest as a mixer that handles categorical and binary targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: The Mixer Interface\n",
    "\n",
    "The Mixer interface is defined by the `BaseMixer` class, a mixer needs methods for 4 tasks:\n",
    "* fitting (`fit`)\n",
    "* predicting (`__call__`)\n",
    "* construction (`__init__`)\n",
    "* partial fitting (`partial_fit`), though this one is optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Writing our mixer\n",
    "\n",
    "I'm going to create a file called `random_forest_mixer.py` inside `/etc/lightwood_modules`, this is where lightwood sources custom modules from.\n",
    "\n",
    "Inside of it I'm going to write the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T14:49:42.847353Z",
     "iopub.status.busy": "2021-12-22T14:49:42.845278Z",
     "iopub.status.idle": "2021-12-22T14:49:42.852223Z",
     "shell.execute_reply": "2021-12-22T14:49:42.852720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing random_forest_mixer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile random_forest_mixer.py\n",
    "\n",
    "from lightwood.mixer import BaseMixer\n",
    "from lightwood.api.types import PredictionArguments\n",
    "from lightwood.data.encoded_ds import EncodedDs, ConcatedEncodedDs\n",
    "from lightwood import dtype\n",
    "from lightwood.encoder import BaseEncoder\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class RandomForestMixer(BaseMixer):\n",
    "    clf: RandomForestClassifier\n",
    "\n",
    "    def __init__(self, stop_after: int, dtype_dict: dict, target: str, target_encoder: BaseEncoder):\n",
    "        super().__init__(stop_after)\n",
    "        self.target_encoder = target_encoder\n",
    "        # Throw in case someone tries to use this for a problem that's not classification, I'd fail anyway, but this way the error message is more intuitive\n",
    "        if dtype_dict[target] not in (dtype.categorical, dtype.binary):\n",
    "            raise Exception(f'This mixer can only be used for classification problems! Got target dtype {dtype_dict[target]} instead!')\n",
    "\n",
    "        # We could also initialize this in `fit` if some of the parameters depend on the input data, since `fit` is called exactly once\n",
    "        self.clf = RandomForestClassifier(max_depth=30)\n",
    "\n",
    "    def fit(self, train_data: EncodedDs, dev_data: EncodedDs) -> None:\n",
    "        X, Y = [], []\n",
    "        # By default mixers get some train data and a bit of dev data on which to do early stopping or hyper parameter optimization. For this mixer, we don't need dev data, so we're going to concat the two in order to get more training data. Then, we're going to turn them into an sklearn friendly foramat.\n",
    "        for x, y in ConcatedEncodedDs([train_data, dev_data]):\n",
    "            X.append(x.tolist())\n",
    "            Y.append(y.tolist())\n",
    "        self.clf.fit(X, Y)\n",
    "\n",
    "    def __call__(self, ds: EncodedDs,\n",
    "                 args: PredictionArguments = PredictionArguments()) -> pd.DataFrame:\n",
    "        # Turn the data into an sklearn friendly format\n",
    "        X = []\n",
    "        for x, _ in ds:\n",
    "            X.append(x.tolist())\n",
    "\n",
    "        Yh = self.clf.predict(X)\n",
    "\n",
    "        # Lightwood encoders are meant to decode torch tensors, so we have to cast the predictions first\n",
    "        decoded_predictions = self.target_encoder.decode(torch.Tensor(Yh))\n",
    "\n",
    "        # Finally, turn the decoded predictions into a dataframe with a single column called `prediction`. This is the standard behaviour all lightwood mixers use\n",
    "        ydf = pd.DataFrame({'prediction': decoded_predictions})\n",
    "\n",
    "        return ydf\n",
    "\n",
    "    \n",
    "    # We'll skip implementing `partial_fit`, thus making this mixer unsuitable for online training tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using our mixer\n",
    "\n",
    "We're going to use our mixer for diagnosing heart disease using this dataset: [https://github.com/mindsdb/benchmarks/blob/main/benchmarks/datasets/heart_disease/data.csv](https://github.com/mindsdb/benchmarks/blob/main/benchmarks/datasets/heart_disease/data.csv)\n",
    "\n",
    "First, since we don't want to bother writing a Json AI for this dataset from scratch, we're going to let lightwood auto generate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T14:49:42.879486Z",
     "iopub.status.busy": "2021-12-22T14:49:42.877586Z",
     "iopub.status.idle": "2021-12-22T14:49:46.508374Z",
     "shell.execute_reply": "2021-12-22T14:49:46.508841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2001:No torchvision detected, image helpers not supported.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:No torchvision/pillow detected, image encoder not supported\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Analyzing a sample of 298\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:from a total population of 303, this is equivalent to 98.3% of your data.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: age\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column age has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: sex\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column sex has data type binary\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: cp\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column cp has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: trestbps\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column trestbps has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: chol\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column chol has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: fbs\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column fbs has data type binary\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: restecg\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column restecg has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: thalach\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column thalach has data type integer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: exang\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column exang has data type binary\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: oldpeak\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column oldpeak has data type float\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: slope\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column slope has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: ca\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column ca has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: thal\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column thal has data type categorical\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Infering type for: target\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Column target has data type binary\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Finished statistical analysis\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"features\": {\n",
      "        \"age\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"sex\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"BinaryEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"binary\"\n",
      "        },\n",
      "        \"cp\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"trestbps\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"chol\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"fbs\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"BinaryEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"binary\"\n",
      "        },\n",
      "        \"restecg\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"thalach\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"integer\"\n",
      "        },\n",
      "        \"exang\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"BinaryEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"binary\"\n",
      "        },\n",
      "        \"oldpeak\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"NumericEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"float\"\n",
      "        },\n",
      "        \"slope\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"ca\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        },\n",
      "        \"thal\": {\n",
      "            \"encoder\": {\n",
      "                \"module\": \"OneHotEncoder\",\n",
      "                \"args\": {}\n",
      "            },\n",
      "            \"data_dtype\": \"categorical\"\n",
      "        }\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"target\": {\n",
      "            \"data_dtype\": \"binary\",\n",
      "            \"encoder\": {\n",
      "                \"module\": \"BinaryEncoder\",\n",
      "                \"args\": {\n",
      "                    \"is_target\": \"True\",\n",
      "                    \"target_weights\": \"$statistical_analysis.target_weights\"\n",
      "                }\n",
      "            },\n",
      "            \"mixers\": [\n",
      "                {\n",
      "                    \"module\": \"Neural\",\n",
      "                    \"args\": {\n",
      "                        \"fit_on_dev\": true,\n",
      "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\",\n",
      "                        \"search_hyperparameters\": true\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"LightGBM\",\n",
      "                    \"args\": {\n",
      "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\",\n",
      "                        \"fit_on_dev\": true\n",
      "                    }\n",
      "                },\n",
      "                {\n",
      "                    \"module\": \"Regression\",\n",
      "                    \"args\": {\n",
      "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\"\n",
      "                    }\n",
      "                }\n",
      "            ],\n",
      "            \"ensemble\": {\n",
      "                \"module\": \"BestOf\",\n",
      "                \"args\": {\n",
      "                    \"args\": \"$pred_args\",\n",
      "                    \"accuracy_functions\": \"$accuracy_functions\",\n",
      "                    \"ts_analysis\": null\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"problem_definition\": {\n",
      "        \"target\": \"target\",\n",
      "        \"pct_invalid\": 2,\n",
      "        \"unbias_target\": true,\n",
      "        \"seconds_per_mixer\": 57024.0,\n",
      "        \"seconds_per_encoder\": null,\n",
      "        \"expected_additional_time\": 0.1056814193725586,\n",
      "        \"time_aim\": 259200,\n",
      "        \"target_weights\": null,\n",
      "        \"positive_domain\": false,\n",
      "        \"timeseries_settings\": {\n",
      "            \"is_timeseries\": false,\n",
      "            \"order_by\": null,\n",
      "            \"window\": null,\n",
      "            \"group_by\": null,\n",
      "            \"use_previous_target\": true,\n",
      "            \"nr_predictions\": null,\n",
      "            \"historical_columns\": null,\n",
      "            \"target_type\": \"\",\n",
      "            \"allow_incomplete_history\": false,\n",
      "            \"eval_cold_start\": true,\n",
      "            \"interval_periods\": []\n",
      "        },\n",
      "        \"anomaly_detection\": false,\n",
      "        \"use_default_analysis\": true,\n",
      "        \"ignore_features\": [],\n",
      "        \"fit_on_all\": true,\n",
      "        \"strict_mode\": true,\n",
      "        \"seed_nr\": 420\n",
      "    },\n",
      "    \"identifiers\": {},\n",
      "    \"accuracy_functions\": [\n",
      "        \"balanced_accuracy_score\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition, json_ai_from_problem, load_custom_module\n",
    "import pandas as pd\n",
    "\n",
    "# load the code\n",
    "load_custom_module('random_forest_mixer.py')\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/heart_disease/data.csv')\n",
    "\n",
    "# define the predictive task\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'target', # column you want to predict\n",
    "})\n",
    "\n",
    "# generate the Json AI intermediate representation from the data and its corresponding settings\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# Print it (you can also put it in a file and edit it there)\n",
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to edit the `mixers` key of this json ai to tell lightwood to use our custom mixer. We can use it together with the others, and have it ensembled with them at the end, or standalone. In this case I'm going to replace all existing mixers with this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T14:49:46.519578Z",
     "iopub.status.busy": "2021-12-22T14:49:46.518003Z",
     "iopub.status.idle": "2021-12-22T14:49:46.520244Z",
     "shell.execute_reply": "2021-12-22T14:49:46.520743Z"
    }
   },
   "outputs": [],
   "source": [
    "json_ai.outputs['target'].mixers = [{\n",
    "    'module': 'random_forest_mixer.RandomForestMixer',\n",
    "    'args': {\n",
    "        'stop_after': '$problem_definition.seconds_per_mixer',\n",
    "        'dtype_dict': '$dtype_dict',\n",
    "        'target': '$target',\n",
    "                'target_encoder': '$encoders[self.target]'\n",
    "\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll generate some code, and finally turn that code into a predictor object and fit it on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T14:49:46.527292Z",
     "iopub.status.busy": "2021-12-22T14:49:46.526587Z",
     "iopub.status.idle": "2021-12-22T14:49:46.842402Z",
     "shell.execute_reply": "2021-12-22T14:49:46.841856Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2001:Unable to import black formatter, predictor code might be a bit ugly.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T14:49:46.847413Z",
     "iopub.status.busy": "2021-12-22T14:49:46.846815Z",
     "iopub.status.idle": "2021-12-22T14:49:51.219552Z",
     "shell.execute_reply": "2021-12-22T14:49:51.219017Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2001:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Performing statistical analysis on data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Starting statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Finished statistical analysis\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Cleaning the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Splitting the data into train/test\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Preparing the encoders\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 1\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 2\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 3\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 4\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 5\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 6\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 7\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 8\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 9\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 10\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 11\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 12\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 13\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoder prepping dict length of: 14\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoding UNKNOWN categories as index 0\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoding UNKNOWN categories as index 0\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoding UNKNOWN categories as index 0\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoding UNKNOWN categories as index 0\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Encoding UNKNOWN categories as index 0\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: target\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: age\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: sex\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: cp\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: trestbps\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: chol\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: fbs\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: restecg\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: thalach\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: exang\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: oldpeak\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: slope\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: ca\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Done running for: thal\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Featurizing the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Training the mixers\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Ensembling the mixer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Mixer: RandomForestMixer got accuracy: 0.8348214285714286\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Picked best mixer: RandomForestMixer\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Analyzing the ensemble of mixers\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:The block ICP is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:The block AccStats is now running its analyze() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Adjustment on validation requested.\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Updating the mixers\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "predictor.learn(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the trained predictor to make some predictions, or save it to a pickle for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T14:49:51.227646Z",
     "iopub.status.busy": "2021-12-22T14:49:51.227046Z",
     "iopub.status.idle": "2021-12-22T14:49:51.399602Z",
     "shell.execute_reply": "2021-12-22T14:49:51.400103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO:lightwood-2001:Dropping features: []\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Cleaning the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:Featurizing the data\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:The block ICP is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:The block AccStats is now running its explain() method\u001b[0m\n",
      "\u001b[32mINFO:lightwood-2001:AccStats.explain() has not been implemented, no modifications will be done to the data insights.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prediction  confidence\n",
      "0          1        0.97\n",
      "1          0        0.98\n",
      "2          1        0.94\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(pd.DataFrame({\n",
    "    'age': [63, 15, None],\n",
    "    'sex': [1, 1, 0],\n",
    "    'thal': [3, 1, 1]\n",
    "}))\n",
    "print(predictions)\n",
    "\n",
    "predictor.save('my_custom_heart_disease_predictor.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, all it takes to solve a predictive problem with lightwood using your own custom mixer."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
