

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Introduction &mdash; lightwood 1.6.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: white" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/mindsdblogo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.6.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../lightwood_philosophy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Lightwood</span> <span class="pre">Philosophy</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Tutorials</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">API</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">Data</span></code></a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">lightwood</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Introduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/tutorials/tutorial_update_models/Tutorial -- Update a predictor.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Introduction">
<h1>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we will go through an example to update a preexisting model. This might be useful when you come across additional data that you would want to consider, without having to train a model from scratch.</p>
<p>The main abstraction that Lightwood offers for this is the <code class="docutils literal notranslate"><span class="pre">BaseMixer.partial_fit()</span></code> method. To call it, you need to pass new training data and a held-out dev subset for internal mixer usage (e.g. early stopping). If you are using an aggregate ensemble, it’s likely you will want to do this for every single mixer. The convienient <code class="docutils literal notranslate"><span class="pre">PredictorInterface.adjust()</span></code> does this automatically for you.</p>
</div>
<div class="section" id="Initial-model-training">
<h1>Initial model training<a class="headerlink" href="#Initial-model-training" title="Permalink to this headline">¶</a></h1>
<p>First, let’s train a Lightwood predictor for the <code class="docutils literal notranslate"><span class="pre">concrete</span> <span class="pre">strength</span></code> dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">lightwood.api.high_level</span> <span class="kn">import</span> <span class="n">ProblemDefinition</span><span class="p">,</span> <span class="n">json_ai_from_problem</span><span class="p">,</span> <span class="n">predictor_from_json_ai</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/mindsdb/lightwood/staging/tests/data/concrete_strength.csv&#39;</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>
<span class="n">update_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train dataframe shape: </span><span class="si">{</span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Update dataframe shape: </span><span class="si">{</span><span class="n">update_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test dataframe shape: </span><span class="si">{</span><span class="n">test_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train dataframe shape: (206, 10)
Update dataframe shape: (618, 10)
Test dataframe shape: (206, 10)
</pre></div></div>
</div>
<p>Note that we have three different data splits.</p>
<p>We will use the <code class="docutils literal notranslate"><span class="pre">training</span></code> split for the initial model training. As you can see, it’s only a 20% of the total data we have. The <code class="docutils literal notranslate"><span class="pre">update</span></code> split will be used as training data to adjust/update our model. Finally, the held out <code class="docutils literal notranslate"><span class="pre">test</span></code> set will give us a rough idea of the impact our updating procedure has on the model’s predictive capabilities.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Define predictive task and predictor</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;concrete_strength&#39;</span>
<span class="n">pdef</span> <span class="o">=</span> <span class="n">ProblemDefinition</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span> <span class="s1">&#39;time_aim&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">})</span>
<span class="n">jai</span> <span class="o">=</span> <span class="n">json_ai_from_problem</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">pdef</span><span class="p">)</span>

<span class="c1"># We will keep the architecture simple: a single neural mixer, and a `BestOf` ensemble:</span>
<span class="n">jai</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">mixers</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="s2">&quot;Neural&quot;</span><span class="p">,</span>
    <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;fit_on_dev&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s2">&quot;stop_after&quot;</span><span class="p">:</span> <span class="s2">&quot;$problem_definition.seconds_per_mixer&quot;</span><span class="p">,</span>
        <span class="s2">&quot;search_hyperparameters&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}]</span>

<span class="n">jai</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;module&quot;</span><span class="p">:</span> <span class="s2">&quot;BestOf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="s2">&quot;$pred_args&quot;</span><span class="p">,</span>
        <span class="s2">&quot;accuracy_functions&quot;</span><span class="p">:</span> <span class="s2">&quot;$accuracy_functions&quot;</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Build and train the predictor</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">predictor_from_json_ai</span><span class="p">(</span><span class="n">jai</span><span class="p">)</span>
<span class="n">predictor</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-3528:Dropping features: []</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Analyzing a sample of 979</span>
<span class="ansi-green-fg">INFO:lightwood-3528:from a total population of 1030, this is equivalent to 95.0% of your data.</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: id</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column id has data type integer</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: cement</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column cement has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: slag</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column slag has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: flyAsh</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column flyAsh has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: water</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column water has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: superPlasticizer</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column superPlasticizer has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: coarseAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column coarseAggregate has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: fineAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column fineAggregate has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: age</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column age has data type integer</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Infering type for: concrete_strength</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Column concrete_strength has data type float</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Finished statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Unable to import black formatter, predictor code might be a bit ugly.</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Dropping features: []</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Performing statistical analysis on data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Starting statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Finished statistical analysis</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Cleaning the data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Splitting the data into train/test</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Preparing the encoders</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 1</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 2</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 3</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 4</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 5</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 6</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 7</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 8</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 9</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Encoder prepping dict length of: 10</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: concrete_strength</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: id</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: cement</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: slag</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: flyAsh</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: water</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: superPlasticizer</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: coarseAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: fineAggregate</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Done running for: age</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Featurizing the data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Training the mixers</span>
/opt/hostedtoolcache/Python/3.9.8/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
/opt/hostedtoolcache/Python/3.9.8/x64/lib/python3.9/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:
        addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
        addcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1025.)
  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 7.6965460777282715 with learning rate 0.0001</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 6.121406555175781 with learning rate 0.00014</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 5.7169036865234375 with learning rate 0.00019599999999999997</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 4.907417297363281 with learning rate 0.00027439999999999995</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 3.7602124214172363 with learning rate 0.0003841599999999999</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 1.8155415058135986 with learning rate 0.0005378239999999999</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 3.7833189964294434 with learning rate 0.0007529535999999998</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss of 8.216030359268188 with learning rate 0.0010541350399999995</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Found learning rate of: 0.0005378239999999999</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 1: 0.7302287817001343</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 2: 0.9203718900680542</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 3: 0.8405624032020569</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 4: 0.7608697414398193</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 5: 0.682328462600708</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 6: 0.6068087220191956</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 7: 0.4470987617969513</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 8: 0.39335447549819946</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 9: 0.34977608919143677</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 10: 0.3151412010192871</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 11: 0.28799620270729065</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 12: 0.2667107582092285</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 13: 0.2335403561592102</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 14: 0.21926473081111908</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 15: 0.20496903359889984</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 16: 0.190594881772995</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 17: 0.17612507939338684</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 18: 0.16138313710689545</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 19: 0.12839831411838531</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 20: 0.11621233820915222</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 21: 0.10669230669736862</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 22: 0.0995490625500679</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 23: 0.09420689940452576</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 24: 0.09003914892673492</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 25: 0.08349904417991638</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 26: 0.08220995217561722</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 27: 0.08120816200971603</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 28: 0.08048582822084427</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 29: 0.07996374368667603</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 30: 0.07936406880617142</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 31: 0.07869087904691696</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 32: 0.07849358767271042</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 33: 0.07820076495409012</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 34: 0.07790302485227585</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 35: 0.07746117562055588</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 36: 0.0766073614358902</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 37: 0.07440942525863647</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 38: 0.07304741442203522</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 39: 0.07175708562135696</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 40: 0.0706695094704628</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 41: 0.06960801780223846</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 42: 0.06830630451440811</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 43: 0.06553896516561508</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 44: 0.06447521597146988</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 45: 0.06355088204145432</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 46: 0.06285690516233444</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 47: 0.0621829479932785</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 48: 0.061278343200683594</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 49: 0.05949181690812111</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 50: 0.058798898011446</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 51: 0.058218952268362045</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 52: 0.057854726910591125</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 53: 0.05746406316757202</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 54: 0.05683555826544762</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 55: 0.055697664618492126</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 56: 0.05525225028395653</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 57: 0.0549074150621891</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 58: 0.05476728081703186</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 59: 0.054551925510168076</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 60: 0.05409771949052811</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 61: 0.05336079001426697</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 62: 0.05306011438369751</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 63: 0.052854686975479126</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 64: 0.052855443209409714</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 65: 0.05273968353867531</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 66: 0.05239949747920036</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 67: 0.05194813385605812</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 68: 0.05178629979491234</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 69: 0.051711175590753555</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 70: 0.051842063665390015</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 71: 0.05181187018752098</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 72: 0.05157443508505821</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 73: 0.05137108266353607</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 74: 0.05131782591342926</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 75: 0.05133718252182007</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 76: 0.05156173184514046</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Ensembling the mixer</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Mixer: Neural got accuracy: 0.5960596686591051</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Picked best mixer: Neural</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Analyzing the ensemble of mixers</span>
<span class="ansi-green-fg">INFO:lightwood-3528:The block ICP is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-3528:The block AccStats is now running its analyze() method</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Adjustment on validation requested.</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Updating the mixers</span>
/opt/hostedtoolcache/Python/3.9.8/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 1: 0.06780618578195571</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 2: 0.07079223617911339</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 3: 0.07359219342470169</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 4: 0.07052805125713349</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 5: 0.07367645800113679</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Train and get predictions for the held out test set</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-3528:Dropping features: []</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Cleaning the data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Featurizing the data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-3528:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-3528:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prediction</th>
      <th>truth</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>52.993881</td>
      <td>71.30</td>
      <td>0.9991</td>
      <td>32.340706</td>
      <td>73.647056</td>
    </tr>
    <tr>
      <th>1</th>
      <td>27.877298</td>
      <td>39.60</td>
      <td>0.9991</td>
      <td>7.224123</td>
      <td>48.530473</td>
    </tr>
    <tr>
      <th>2</th>
      <td>18.540179</td>
      <td>10.79</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>39.193354</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16.238102</td>
      <td>4.83</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>36.891276</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32.959752</td>
      <td>47.71</td>
      <td>0.9991</td>
      <td>12.306577</td>
      <td>53.612927</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>201</th>
      <td>47.220826</td>
      <td>40.93</td>
      <td>0.9991</td>
      <td>26.567652</td>
      <td>67.874001</td>
    </tr>
    <tr>
      <th>202</th>
      <td>42.638142</td>
      <td>52.82</td>
      <td>0.9991</td>
      <td>21.984967</td>
      <td>63.291317</td>
    </tr>
    <tr>
      <th>203</th>
      <td>31.631880</td>
      <td>39.66</td>
      <td>0.9991</td>
      <td>10.978705</td>
      <td>52.285054</td>
    </tr>
    <tr>
      <th>204</th>
      <td>29.147330</td>
      <td>13.29</td>
      <td>0.9991</td>
      <td>8.494156</td>
      <td>49.800505</td>
    </tr>
    <tr>
      <th>205</th>
      <td>38.615127</td>
      <td>17.84</td>
      <td>0.9991</td>
      <td>17.961952</td>
      <td>59.268302</td>
    </tr>
  </tbody>
</table>
<p>206 rows × 5 columns</p>
</div></div>
</div>
<div class="section" id="Updating-the-predictor">
<h2>Updating the predictor<a class="headerlink" href="#Updating-the-predictor" title="Permalink to this headline">¶</a></h2>
<p>As previously mentioned, you can update any given mixer with a <code class="docutils literal notranslate"><span class="pre">BaseMixer.partial_fit()</span></code> call. If you have multiple mixers and want to update them all at once, you should use <code class="docutils literal notranslate"><span class="pre">PredictorInterface.adjust()</span></code>.</p>
<p>For both of these methods, two encoded datasources are needed as input (for <code class="docutils literal notranslate"><span class="pre">adjust</span></code> you need to wrap them in a dictionary with ‘old’ and ‘new’ keys).</p>
<p>Let’s <code class="docutils literal notranslate"><span class="pre">adjust</span></code> our predictor:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">lightwood.data</span> <span class="kn">import</span> <span class="n">EncodedDs</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">EncodedDs</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">update_ds</span> <span class="o">=</span> <span class="n">EncodedDs</span><span class="p">(</span><span class="n">predictor</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="n">update_df</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="n">predictor</span><span class="o">.</span><span class="n">adjust</span><span class="p">({</span><span class="s1">&#39;old&#39;</span><span class="p">:</span> <span class="n">train_ds</span><span class="p">,</span> <span class="s1">&#39;new&#39;</span><span class="p">:</span> <span class="n">update_ds</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-3528:Updating the mixers</span>
/opt/hostedtoolcache/Python/3.9.8/x64/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(&#34;torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.&#34;)
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 1: 0.06395960412919521</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 2: 0.0760517530143261</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 3: 0.06467204913496971</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 4: 0.0686721174667279</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 5: 0.059960046162207924</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 6: 0.05878346599638462</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 7: 0.059159028654297195</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 8: 0.05405611855288347</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 9: 0.054099527498086296</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Loss @ epoch 10: 0.05619463324546814</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">new_predictions</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span>
<span class="n">new_predictions</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-green-fg">INFO:lightwood-3528:Dropping features: []</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Cleaning the data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:Featurizing the data</span>
<span class="ansi-green-fg">INFO:lightwood-3528:The block ICP is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-3528:The block AccStats is now running its explain() method</span>
<span class="ansi-green-fg">INFO:lightwood-3528:AccStats.explain() has not been implemented, no modifications will be done to the data insights.</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prediction</th>
      <th>truth</th>
      <th>confidence</th>
      <th>lower</th>
      <th>upper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>54.147115</td>
      <td>71.30</td>
      <td>0.9991</td>
      <td>33.493941</td>
      <td>74.800290</td>
    </tr>
    <tr>
      <th>1</th>
      <td>29.181826</td>
      <td>39.60</td>
      <td>0.9991</td>
      <td>8.528651</td>
      <td>49.835001</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16.265376</td>
      <td>10.79</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>36.918551</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.720440</td>
      <td>4.83</td>
      <td>0.9991</td>
      <td>0.000000</td>
      <td>34.373615</td>
    </tr>
    <tr>
      <th>4</th>
      <td>32.030441</td>
      <td>47.71</td>
      <td>0.9991</td>
      <td>11.377266</td>
      <td>52.683616</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>201</th>
      <td>42.245359</td>
      <td>40.93</td>
      <td>0.9991</td>
      <td>21.592184</td>
      <td>62.898534</td>
    </tr>
    <tr>
      <th>202</th>
      <td>37.356423</td>
      <td>52.82</td>
      <td>0.9991</td>
      <td>16.703248</td>
      <td>58.009598</td>
    </tr>
    <tr>
      <th>203</th>
      <td>29.892014</td>
      <td>39.66</td>
      <td>0.9991</td>
      <td>9.238839</td>
      <td>50.545189</td>
    </tr>
    <tr>
      <th>204</th>
      <td>28.064979</td>
      <td>13.29</td>
      <td>0.9991</td>
      <td>7.411804</td>
      <td>48.718153</td>
    </tr>
    <tr>
      <th>205</th>
      <td>35.456562</td>
      <td>17.84</td>
      <td>0.9991</td>
      <td>14.803388</td>
      <td>56.109737</td>
    </tr>
  </tbody>
</table>
<p>206 rows × 5 columns</p>
</div></div>
</div>
<p>Nice! Our predictor was updated, and new predictions are looking good. Let’s compare the old and new accuracies:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="n">old_acc</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;truth&#39;</span><span class="p">],</span> <span class="n">predictions</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>
<span class="n">new_acc</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">new_predictions</span><span class="p">[</span><span class="s1">&#39;truth&#39;</span><span class="p">],</span> <span class="n">new_predictions</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Old Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">old_acc</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">New Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">new_acc</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Old Accuracy: 0.589
New Accuracy: 0.632
</pre></div></div>
</div>
<p>After updating, we see an increase in the R2 score of predictions for the held out test set.</p>
</div>
<div class="section" id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h2>
<p>We have gone through a simple example of how Lightwood predictors can leverage newly acquired data to improve their predictions. The interface for doing so is fairly simple, requiring only some new data and a single call to update.</p>
<p>You can further customize the logic for updating your mixers by modifying the <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> methods in them.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017-2021, MindsDB.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>